1
import math
import numpy as np
import matplotlib.pyplot as plt

def activate(inputs, weights):
    h = sum(x * w for x, w in zip(inputs, weights))
    return [
        sigmoid(h),
        relu(h),
        tanh(h),
        linear(h),
        unit_step(h),
        sign(h)
    ]

def sigmoid(x):
    return 1 / (1 + math.exp(-x))

def relu(x):
    return max(0, x)

def tanh(x):
    return np.tanh(x)

def linear(x):
    return x

def unit_step(x):
    return 1 if x > 0 else 0

def sign(x):
    return 1 if x > 0 else (-1 if x < 0 else 0)



if __name__ == "__main__":
    inputs = [.5, .3, .2]
    weights = [.4, .7, .2]
    output = activate(inputs, weights)
    print("sigmoid: ", output[0])
    print("ReLu: ", output[1])
    print("tanh: ", output[2])
    print("linear: ", output[3])
    print("unit step: ", output[4])
    print("sign: ", output[5])

x_values = np.linspace(-10, 10, 400) #(start, stop, num) --> step size = (stop-start)/(num-1) = (10-(-10))/(400-1) =
def plot_activation(activation, name):
  y_values = [activation(x) for x in x_values]
  plt.figure(figsize=(8, 5))
  plt.plot(x_values, y_values, label=name, color='r')
  plt.title(f"{name} Activation Function")
  plt.xlabel('Input')
  plt.ylabel("Output")
  plt.grid()
  plt.legend()
  plt.show()
  print()

plot_activation(sigmoid, "Sigmoid")
plot_activation(relu, "Relu")
plot_activation(tanh, 'tanh')
plot_activation(linear, "linear")
plot_activation(unit_step, "Unit Step")
plot_activation(sign, "Sign")


2
import numpy as np

class Perceptron:
    def __init__(self, learning_rate=0.01, epochs=100):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        self.weights = np.zeros(X.shape[1])
        self.bias = 0.0

        for epoch in range(self.epochs):
            for i in range(X.shape[0]):
                # Compute the weighted sum and apply the step function
                prediction = self.predict(X[i])
                error = y[i] - prediction
                self.weights += self.learning_rate * error * X[i]
                self.bias += self.learning_rate * error

    def predict(self, x):
        weighted_sum = np.dot(x, self.weights) + self.bias
        return 1 if weighted_sum >= 0 else 0

# Training data
X_train = np.array([[2, 3], [1, 4], [3, 5], [4, 2]])
y_train = np.array([0, 0, 1, 1])

# Create and train the perceptron
perceptron = Perceptron(learning_rate=0.01, epochs=100)
perceptron.fit(X_train, y_train)

# New data point for prediction
new_data_point = np.array([2, 4])
prediction = perceptron.predict(new_data_point)
print(f"Prediction for {new_data_point}: {prediction}")


3
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
import matplotlib.pyplot as plt

# Load the Iris dataset
iris = load_iris()

# Convert data and target arrays into pandas DataFrame
data_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
target_df = pd.DataFrame(data=iris.target, columns=['target'])

# Concatenate data and target DataFrames
df = pd.concat([data_df, target_df], axis=1)

# Print head and shape of the dataset
print("Head of the dataset:")
print(df.head())
print("\nShape of the dataset:")
print(df.shape)

# Split data into features (X) and labels (y)
X, y = df.drop('target', axis=1), df['target']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the neural network model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model
history = model.fit(
    X_train_scaled, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.1
)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test_scaled, y_test)
print(f'\nTest accuracy: {accuracy:.2f}')

# Plot the training history for accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

# Plot the training history for loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.grid(True)
plt.show()



4
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD
import matplotlib.pyplot as plt

# Load Iris dataset
iris_data = load_iris()
X = iris_data.data
y = iris_data.target

# One-hot encode target variable
onehot_encoder = OneHotEncoder(sparse_output=False)
y_onehot = onehot_encoder.fit_transform(y.reshape(-1, 1))

# Split dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define a simple neural network model
def create_model():
    model = Sequential([
        Dense(64, input_shape=(X_train_scaled.shape[1],), activation='relu'),
        Dense(32, activation='relu'),
        Dense(3, activation='softmax')  # Output layer for 3 classes
    ])
    return model

# Compile model with Gradient Descent optimizer
gd_optimizer = SGD(learning_rate=0.01)
gd_model = create_model()
gd_model.compile(optimizer=gd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# Fit the model with Gradient Descent
gd_history = gd_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32,
                          validation_data=(X_test_scaled, y_test), verbose=0)

# Compile model with Stochastic Gradient Descent optimizer
sgd_optimizer = SGD(learning_rate=0.01)
sgd_model = create_model()
sgd_model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# Fit the model with Stochastic Gradient Descent
sgd_history = sgd_model.fit(X_train_scaled, y_train, epochs=50, batch_size=1,
                            validation_data=(X_test_scaled, y_test), verbose=0)

# Plot training history for Gradient Descent
plt.figure(figsize=(10, 6))
plt.plot(gd_history.history['loss'], label='Train Loss (GD)')
plt.plot(gd_history.history['val_loss'], label='Validation Loss (GD)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss (GD)')
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(gd_history.history['accuracy'], label='Train Accuracy (GD)')
plt.plot(gd_history.history['val_accuracy'], label='Validation Accuracy (GD)')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy (GD)')
plt.show()

# Plot training history for Stochastic Gradient Descent
plt.figure(figsize=(10, 6))
plt.plot(sgd_history.history['loss'], label='Train Loss (SGD)')
plt.plot(sgd_history.history['val_loss'], label='Validation Loss (SGD)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss (SGD)')
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(sgd_history.history['accuracy'], label='Train Accuracy (SGD)')
plt.plot(sgd_history.history['val_accuracy'], label='Validation Accuracy (SGD)')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy (SGD)')
plt.show()





5
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import regularizers

# Simulating a dataset for multitask learning (e.g., regression tasks)
# Task 1: Predict 'y1' and Task 2: Predict 'y2'
X_train = np.random.rand(1000, 10)
y_train_1 = X_train[:, 0] + X_train[:, 1]  # First regression task
y_train_2 = X_train[:, 1] - X_train[:, 2]  # Second regression task

X_val = np.random.rand(200, 10)
y_val_1 = X_val[:, 0] + X_val[:, 1]
y_val_2 = X_val[:, 1] - X_val[:, 2]

# Build a multitask neural network model with dropout and gradient clipping
def build_model(input_dim):
    input_layer = Input(shape=(input_dim,))

    x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(input_layer)
    x = Dropout(0.5)(x)  # Applying dropout to prevent overfitting
    x = Dense(64, activation='relu')(x)
    x = Dropout(0.5)(x)

    # Task 1: Output layer for first task (regression)
    output_1 = Dense(1, name='output_1')(x)

    # Task 2: Output layer for second task (regression)
    output_2 = Dense(1, name='output_2')(x)

    model = Model(inputs=input_layer, outputs=[output_1, output_2])

    return model

# Initialize model
model = build_model(input_dim=10)

# Compile the model with multiple loss functions for multitask learning
model.compile(optimizer=Adam(learning_rate=0.001),
              loss={'output_1': 'mse', 'output_2': 'mse'},
              metrics={'output_1': 'mae', 'output_2': 'mae'})

# Early stopping based on validation loss
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Gradient Clipping for preventing exploding gradients
optimizer = Adam(learning_rate=0.001, clipvalue=1.0)  # Clip gradients to a value of 1.0
model.compile(optimizer=optimizer,
              loss={'output_1': 'mse', 'output_2': 'mse'},
              metrics={'output_1': 'mae', 'output_2': 'mae'})

# Train the model with multitask learning, dropout, and early stopping
history = model.fit(X_train, {'output_1': y_train_1, 'output_2': y_train_2},
                    validation_data=(X_val, {'output_1': y_val_1, 'output_2': y_val_2}),
                    epochs=100,
                    batch_size=32,
                    callbacks=[early_stopping])

# Plot the training and validation loss
import matplotlib.pyplot as plt

# Plot training and validation loss for both tasks
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss during training')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot training and validation accuracy for both tasks
plt.plot(history.history['output_1_mae'], label='Train Task 1 MAE')
plt.plot(history.history['val_output_1_mae'], label='Val Task 1 MAE')
plt.plot(history.history['output_2_mae'], label='Train Task 2 MAE')
plt.plot(history.history['val_output_2_mae'], label='Val Task 2 MAE')
plt.title('Accuracy during training for each task')
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.legend()
plt.show()




6
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Load and preprocess the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize the images to [0, 1] range
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Reshape images to (28, 28, 1) because MNIST images are grayscale
x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))

# One-hot encode the labels
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Build the CNN model
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),
    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, batch_size=128, verbose=2)

# Evaluate the model
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f'Test accuracy: {test_acc:.4f}')

# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')

plt.show()

# Predict on the test set
predictions = model.predict(x_test)

# Convert predictions to labels
predicted_labels = [tf.argmax(prediction).numpy() for prediction in predictions]

plt.figure(figsize=(10, 4))
num_images = 3
for i in range(num_images):
    plt.subplot(1, num_images, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Predicted: {predicted_labels[i]}, True: {tf.argmax(y_test[i]).numpy()}")
    plt.axis('off')
plt.show()





7
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

# Set parameters
vocab_size = 10000
max_length = 200

# Load IMDb dataset
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)

# Pad sequences to ensure uniform input size
x_train = pad_sequences(x_train, maxlen=max_length)
x_test = pad_sequences(x_test, maxlen=max_length)

# Build the model
model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),
    SimpleRNN(128, activation='tanh', return_sequences=False),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))

# Evaluate the model
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Sentiment prediction for a sample review
sample_review = "This movie was fantastic! The characters were well-developed and the plot was thrilling."

# Tokenizer for encoding the review
tokenizer = Tokenizer(num_words=vocab_size)
tokenizer.fit_on_texts(sample_review.lower())  # Fit the tokenizer on the sample text

# Convert the review to a sequence of integers
encoded_review = tokenizer.texts_to_sequences([sample_review.lower()])
padded_review = pad_sequences(encoded_review, maxlen=max_length)

# Predict sentiment
prediction = model.predict(padded_review)
sentiment = "Positive" if prediction[0] > 0.5 else "Negative"
print(f"Predicted Sentiment: {sentiment}")
